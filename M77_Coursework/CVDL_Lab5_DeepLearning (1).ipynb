{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HECoNZ1IHXxG"
   },
   "source": [
    "### Computer Vision and Deep Learning \n",
    "## Lab 4 - Deep Learning Architectures\n",
    "This lab looks into using deep learning for the purpose of image classification and region proposal. We will also utilise RNN architectures to learn temporal information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R28r7wqAHXxI"
   },
   "source": [
    "## Imports <a id=\"imports\"></a>\n",
    "The following section defines the imports used for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSfykKrzHXxJ"
   },
   "outputs": [],
   "source": [
    "# For ndarray handling:\n",
    "import numpy as np\n",
    "\n",
    "# For plotting:\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For deep learning functionality\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaZgmJTGHXxK"
   },
   "source": [
    "## Load the MNIST digit recognition dataset\n",
    "This dataset is comprised of ~70,000 28x28 grayscale images of handwritten numerical digits 0-9. It is a common baseline dataset used in the evaluation of many recognition methodologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "Id-8wplJHXxL",
    "outputId": "6bf86c87-1790-4629-919c-372bb4e58492"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Get the one-hot encoded labels\n",
    "n_class = len(np.unique(y_train))\n",
    "Y_train = np.eye(n_class)[y_train]\n",
    "Y_test = np.eye(n_class)[y_test]\n",
    "\n",
    "plt.figure()\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
    "    plt.title(f'Digit: {y_train[i]}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TlKoD8uHXxM"
   },
   "source": [
    "***\n",
    "\n",
    "<center><H1> Task 1: Further Deep Learning Methods </H1></center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfHedGk5HXxN"
   },
   "source": [
    "## Using a Neural Network\n",
    "Here we will use a normal neural network architecture, one which does not explicitly utilize the spatial topology of the input domain (i.e. the 2D that images reside on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5K97XWtlHXxN",
    "outputId": "d7934465-8055-442e-81e0-a89096b91a51"
   },
   "outputs": [],
   "source": [
    "# Turn our images into 1D vectors by unravelling them\n",
    "X_train_NN = X_train.reshape(X_train.shape[0], 784)\n",
    "X_test_NN = X_test.reshape(X_test.shape[0], 784)\n",
    "X_train_NN = X_train_NN.astype('float32')\n",
    "X_test_NN = X_test_NN.astype('float32')\n",
    "\n",
    "# Normalize the data to help with training\n",
    "X_train_NN /= 255\n",
    "X_test_NN /= 255\n",
    "\n",
    "# Create the model using Sequential object\n",
    "model = Sequential()\n",
    "\n",
    "# Create the first hidden layer, this takes an argument of the input data shape (i.e. number of features)\n",
    "model.add(Dense(512, input_shape=(X_train_NN.shape[1], )))\n",
    "model.add(Activation('relu'))                         \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Create the next hidden layer, this takes an argument of the input data shape (i.e. number of features)\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))                         \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Create the output layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model ready for training\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_NN, Y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkhZ4i8wHXxO"
   },
   "source": [
    "## Plot the training statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UceADL13HXxP"
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3V7tdASmHXxQ"
   },
   "source": [
    "## Evaluate our Neural Network\n",
    "Here we will predict the class probability for each test sample. We can then compare this to our ground truth and see the performance of our model on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tkYl1THHXxQ"
   },
   "outputs": [],
   "source": [
    "predicted_probability = model.predict(X_test_NN)\n",
    "predicted_classes = np.argmax(predicted_probability, axis=-1)\n",
    "\n",
    "correct_preds = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_preds = np.nonzero(predicted_classes != y_test)[0]\n",
    "print(f'{len(correct_preds)} classified correctly')\n",
    "print(f'{len(incorrect_preds)} classified incorrectly')\n",
    "print(f'{len(correct_preds) / len(y_test) * 100}% of test set classified correctly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGLouTgjHXxR"
   },
   "outputs": [],
   "source": [
    "print('Correctly classified:')\n",
    "for i_correct in correct_preds[0:5]:\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(range(n_class), predicted_probability[i_correct], tick_label=range(n_class))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(X_test[i_correct], cmap='gray', interpolation='none')\n",
    "    plt.title(f'Truth: {y_test[i_correct]}, Predicted: {predicted_classes[i_correct]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "print('Incorrectly classified:')\n",
    "for i_incorrect in incorrect_preds[0:5]:\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(range(n_class), predicted_probability[i_incorrect], tick_label=range(n_class))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(X_test[i_incorrect], cmap='gray', interpolation='none')\n",
    "    plt.title(f'Truth: {y_test[i_incorrect]}, Predicted: {predicted_classes[i_incorrect]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21I-UyNuHXxS"
   },
   "source": [
    "## Using a Convolutional Neural Network\n",
    "Here we will use a convolutional neural network architecture, one which does explicitly utilize the spatial topology of the input domain (i.e. the 2D that images reside on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRi2-BbvHXxS"
   },
   "outputs": [],
   "source": [
    "# Normalize the data to help with training\n",
    "X_train_CNN = np.expand_dims(X_train, axis=-1)\n",
    "X_test_CNN = np.expand_dims(X_test, axis=-1)\n",
    "X_train_CNN = X_train_CNN.astype('float32')\n",
    "X_test_CNN = X_test_CNN.astype('float32')\n",
    "X_train_CNN /= 255\n",
    "X_test_CNN /= 255\n",
    "\n",
    "# Create the model using Sequential object\n",
    "model = Sequential()\n",
    "\n",
    "# Create the first hidden layer, this takes an argument of the input data shape (i.e. number of features)\n",
    "model.add(Conv2D(10, (5, 5), input_shape=(X_train_CNN.shape[1], X_train_CNN.shape[2], 1)))\n",
    "model.add(Activation('relu'))                         \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Create the next hidden layer, this takes an argument of the input data shape (i.e. number of features)\n",
    "model.add(MaxPool2D())\n",
    "model.add(Activation('relu'))                         \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Create the dense head layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Create the output layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model ready for training\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_CNN, Y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yHQ3XhcHXxT"
   },
   "outputs": [],
   "source": [
    "predicted_probability = model.predict(X_test_CNN)\n",
    "\n",
    "predicted_classes = np.argmax(predicted_probability, axis=-1)\n",
    "\n",
    "correct_preds = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_preds = np.nonzero(predicted_classes != y_test)[0]\n",
    "print(f'{len(correct_preds)} classified correctly')\n",
    "print(f'{len(incorrect_preds)} classified incorrectly')\n",
    "print(f'{len(correct_preds) / len(y_test) * 100}% of test set classified correctly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UKFy2UCHXxU"
   },
   "source": [
    "# Using an RNN\n",
    "Often we can observe data which exhibits some temporal pattern, for example in time-series data such as the reccurance of flu cases, the flight pattern of birds, and even the usage of words in sentences. Such information may have features which are related to eachother over long and/short time periods. In these cases it can often be useful to utilize the temporal domain of the information and incorporate this into our model training scheme. Such models are known as Recurrent Neural Networks, of which there are many flavours and approaches.\n",
    "\n",
    "In this section we will use the MNIST dataset again, but this time reading each row of the image in as a time-step. This replicates the behaviour of a line scanner, where each row is read one-by-one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPtIGHomHXxU"
   },
   "outputs": [],
   "source": [
    "# Normalize the data to help with training\n",
    "X_train_RNN = X_train\n",
    "X_test_RNN = X_test\n",
    "X_train_RNN = X_train_RNN.astype('float32')\n",
    "X_test_RNN = X_test_RNN.astype('float32')\n",
    "X_train_RNN /= 255\n",
    "X_test_RNN /= 255\n",
    "\n",
    "# Create the model using Sequential object\n",
    "model = Sequential()\n",
    "\n",
    "# Create the first hidden layer, this takes an argument of the input data shape (i.e. number of features)\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Activation('tanh'))                         \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Create the output layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model ready for training\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_RNN, Y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqZEl_luHXxU"
   },
   "outputs": [],
   "source": [
    "predicted_probability = model.predict(X_test_RNN)\n",
    "\n",
    "predicted_classes = np.argmax(predicted_probability, axis=-1)\n",
    "\n",
    "correct_preds = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_preds = np.nonzero(predicted_classes != y_test)[0]\n",
    "print(f'{len(correct_preds)} classified correctly')\n",
    "print(f'{len(incorrect_preds)} classified incorrectly')\n",
    "print(f'{len(correct_preds) / len(y_test) * 100}% of test set classified correctly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwX62UE_HXxV",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Using an LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DII2Q9LgHXxV"
   },
   "outputs": [],
   "source": [
    "# Normalize the data to help with training\n",
    "X_train_LSTM = X_train\n",
    "X_test_LSTM = X_test\n",
    "X_train_LSTM = X_train_LSTM.astype('float32')\n",
    "X_test_LSTM = X_test_LSTM.astype('float32')\n",
    "X_train_LSTM /= 255\n",
    "X_test_LSTM /= 255\n",
    "\n",
    "# Create the model using Sequential object\n",
    "model = Sequential()\n",
    "\n",
    "# Create the first hidden layer, this takes an argument of the input data shape (i.e. number of features)\n",
    "model.add(LSTM(8))\n",
    "model.add(Activation('tanh'))                         \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Create the output layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model ready for training\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_RNN, Y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4A9ihN4lHXxW"
   },
   "outputs": [],
   "source": [
    "# Summarize history for accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixWB8cl2HXxX"
   },
   "outputs": [],
   "source": [
    "predicted_probability = model.predict(X_test_LSTM)\n",
    "\n",
    "predicted_classes = np.argmax(predicted_probability, axis=-1)\n",
    "\n",
    "correct_preds = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_preds = np.nonzero(predicted_classes != y_test)[0]\n",
    "print(f'{len(correct_preds)} classified correctly')\n",
    "print(f'{len(incorrect_preds)} classified incorrectly')\n",
    "print(f'{len(correct_preds) / len(y_test) * 100}% of test set classified correctly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtBhhcvMHXxa"
   },
   "source": [
    "***\n",
    "\n",
    "<center><H1> Task 2: Region Proposal Networks </H1></center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-kjUOIFHXxa",
    "tags": []
   },
   "source": [
    "# Using an RCNN\n",
    "So far we have trained networks for the classification task, where it is assumed that our object of interest takes up a respectable portion of the observed input. Note that all of the MNIST images contain only one digit, that digit is centred and appropriately scaled and all of them are light digits on a dark background.\n",
    "\n",
    "In reality we often come across the detection problem, where we wish to both identify and localize our objects in our observations. Think of the face detection problem, we can often see images containing numerous faces at various scales and orientations. There are numerous methods for tackling this problem, but a common niave approach is to perform a sliding window search across the input space, taking localised patches and passing them to a classification model. Depending on the size of the input domain and the sliding operation we perform, this can be a very expensive task which leads to high time complexity.\n",
    "\n",
    "Region Proposal Networks attempt to overcome the issue of large search space traversal by first obtaining regions of interest within the whole input image. These regions of interest can then act as focal points for our classifier to then identify the object.\n",
    "\n",
    "For this task we will modify our MNIST dataset to create larger images within which we have placed our digits. We will then utilise an RCNN pipeline to first identify proposed regions of interest within our scene. We will then use a pre-trained CNN to classify these regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dmybo1G5HXxa"
   },
   "outputs": [],
   "source": [
    "# First we will create a new dataset in which we have MNIST images placed in random places within a larger image.\n",
    "\n",
    "# Create new dataset of images which are 640×480\n",
    "mnist_size = X_train.shape\n",
    "\n",
    "X_train_RPN = np.zeros([mnist_size[0] // 100, 160, 240])\n",
    "X_test_RPN = np.zeros([mnist_size[0] // 100, 160, 240])\n",
    "\n",
    "# Next we will place digits in random XY locations within the larger image space. \n",
    "# To do this we will first get random coordinates, we will then create the bounding box ground truth and then write \n",
    "# the MNIST sample into our larger images. \n",
    "\n",
    "# Training Set:\n",
    "train_xs = np.random.randint(mnist_size[1], X_train_RPN.shape[1] - mnist_size[1], X_train_RPN.shape[0])\n",
    "train_ys = np.random.randint(mnist_size[2], X_train_RPN.shape[2] - mnist_size[2], X_train_RPN.shape[0])\n",
    "train_bbox = np.stack([train_xs - mnist_size[1] // 2, train_ys - mnist_size[2] // 2,\n",
    "                       train_xs + mnist_size[1] // 2, train_ys + mnist_size[2] // 2], axis=1)\n",
    "\n",
    "for i_train in range(X_train_RPN.shape[0]):\n",
    "    X_train_RPN[i_train, train_bbox[i_train, 0]:train_bbox[i_train, 2], \\\n",
    "                         train_bbox[i_train, 1]:train_bbox[i_train, 3]] = X_train[i_train, :, :]\n",
    "\n",
    "# Testing Set:    \n",
    "test_xs = np.random.randint(mnist_size[1], X_test_RPN.shape[1] - mnist_size[1], X_test_RPN.shape[0])\n",
    "test_ys = np.random.randint(mnist_size[2], X_test_RPN.shape[2] - mnist_size[2], X_test_RPN.shape[0])\n",
    "test_bbox = np.stack([test_xs - mnist_size[1] // 2, test_ys - mnist_size[2] // 2,\n",
    "                      test_xs + mnist_size[1] // 2, test_ys + mnist_size[2] // 2], axis=1)\n",
    "    \n",
    "for i_test in range(X_train_RPN.shape[0]):\n",
    "    X_test_RPN[i_test, test_bbox[i_test, 0]:test_bbox[i_test, 2], \\\n",
    "                        test_bbox[i_test, 1]:test_bbox[i_test, 3]] = X_test[i_test, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1G44BJTHXxb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can visualise our new bigger images with truth bounding boxes.\n",
    "for i in range(5):\n",
    "    plt.figure()\n",
    "    ax = plt.imshow(X_train_RPN[i]).axes\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(train_bbox[i, 0:2][::-1], 28, 28, fill=False, color='r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEefmLV6HXxb"
   },
   "outputs": [],
   "source": [
    "# Train a CNN on normal MNIST (28x28) with background class aswell.\n",
    "# Add background class to mnist dataset.\n",
    "n_empty_bg = 600 # number with a zeros background\n",
    "n_random_bg = 100 # number with a random background\n",
    "X_train_with_bg = np.concatenate([X_train, \n",
    "                                  np.zeros([n_empty_bg, X_train.shape[1], X_train.shape[2]]), \n",
    "                                  np.random.rand(n_random_bg, X_train.shape[1], X_train.shape[2])])\n",
    "Y_train_with_bg = np.concatenate([np.c_[Y_train, np.zeros([Y_train.shape[0],1])],\n",
    "                                  np.eye(n_class + 1)[np.zeros(n_empty_bg + n_random_bg, dtype=np.int) + n_class]])\n",
    "X_test_with_bg = X_test\n",
    "Y_test_with_bg = Y_test\n",
    "\n",
    "# Randomly shuffle our data, so that the background class gets mixed into the set.\n",
    "train_shuffle = np.arange(X_train_with_bg.shape[0])\n",
    "np.random.shuffle(train_shuffle)\n",
    "X_train_with_bg = X_train_with_bg[train_shuffle]\n",
    "Y_train_with_bg = Y_train_with_bg[train_shuffle]\n",
    "\n",
    "test_shuffle = np.arange(X_test_with_bg.shape[0])\n",
    "np.random.shuffle(test_shuffle)\n",
    "X_test_with_bg = X_test_with_bg[test_shuffle]\n",
    "Y_test_with_bg = Y_test_with_bg[test_shuffle]\n",
    "\n",
    "# Normalize the sets.\n",
    "X_train_CNN = np.expand_dims(X_train_with_bg, axis=-1)\n",
    "X_test_CNN = np.expand_dims(X_test_with_bg, axis=-1)\n",
    "X_train_CNN = X_train_CNN.astype('float32')\n",
    "X_test_CNN = X_test_CNN.astype('float32')\n",
    "X_train_CNN = X_train_CNN / 255\n",
    "X_test_CNN = X_test_CNN / 255\n",
    "\n",
    "# Update number of classes.\n",
    "n_class += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fr9ljQSKHXxc"
   },
   "outputs": [],
   "source": [
    "# Train our CNN to classify digits and background observations\n",
    "\n",
    "# Create the model using Sequential object\n",
    "model = Sequential()\n",
    "\n",
    "# Create the first hidden layer, this takes an argument of the input data shape (i.e. number of features)\n",
    "model.add(Conv2D(10, (3, 3), padding='same', input_shape=(X_train_CNN.shape[1], X_train_CNN.shape[2], 1)))\n",
    "model.add(Conv2D(10, (3, 3), padding='same'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Activation('relu'))                         \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Create the dense head layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# Create the output layer\n",
    "model.add(Dense(n_class))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model ready for training\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_CNN, Y_train_with_bg, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vWTjv-A3HXxc"
   },
   "outputs": [],
   "source": [
    "# Summarize history for accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kU3sCi0PHXxc",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sliding-window approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5PMIIT5HXxc"
   },
   "outputs": [],
   "source": [
    "# We can now try windowing across the whole image to see if there is a digit present at each location\n",
    "# We will just do this with one image at the moment, to save time\n",
    "\n",
    "print(f'We will visit {np.size(X_train_RPN[0])} pixels using sliding window!')\n",
    "\n",
    "# Loop through images\n",
    "for i_image in range(1):\n",
    "    \n",
    "    # Pad image to allow patch extraction\n",
    "    pad_size = [s // 2 for s in X_train.shape[1:3]]\n",
    "    padded_image = np.pad(X_test_RPN[i_image], pad_size, 'constant', constant_values=(0))\n",
    "\n",
    "    # Loop through pixels and extract patches\n",
    "    patches = []\n",
    "    patch_counter = 0\n",
    "    for i_row in range(pad_size[0], X_train_RPN.shape[1] + pad_size[1]):\n",
    "        for i_col in range(pad_size[1], X_train_RPN.shape[2] + pad_size[0]):\n",
    "            patches.append(padded_image[i_row - pad_size[0]:i_row + pad_size[0], \\\n",
    "                                        i_col - pad_size[1]:i_col + pad_size[1]])\n",
    "            if (patch_counter % 10000) == 0:\n",
    "                print(f'Patch {patch_counter} of {np.size(X_train_RPN[0])}')\n",
    "            patch_counter += 1\n",
    "\n",
    "    # Predict the class for each patch        \n",
    "    patches = np.expand_dims(np.asarray(patches), axis=-1)    \n",
    "    patch_probabilities = model.predict(patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Lpy2ZtFOkH-"
   },
   "outputs": [],
   "source": [
    "# For a single patch, visualise the per-class response of the model\n",
    "predicted_response = np.reshape(patch_probabilities, [X_test_RPN[i_image].shape[0], X_test_RPN[i_image].shape[1], n_class])\n",
    "plt.figure()\n",
    "plt.title(\"Input image\")\n",
    "plt.imshow(X_test_RPN[i_image])\n",
    "for i_class in range(n_class): \n",
    "    plt.figure()\n",
    "    plt.title(f'Segmentation for class {i_class}')\n",
    "    plt.imshow(predicted_response[:, :, i_class])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRRAP3s7HXxd"
   },
   "source": [
    "## Selective Search + CNN detector\n",
    "Here we will utilise selective search to first obtain some regions of interest in our image. We will then use these proposed regions as inputs to our classifier in order to obtain a label for each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-D_HueZPHXxd"
   },
   "outputs": [],
   "source": [
    "# Some additional imports which may be needed for the process\n",
    "import selectivesearch # for selective search\n",
    "import skimage # to reshape the proposals\n",
    "import cv2 # to convert grayscale to color\n",
    "\n",
    "# Loop over images and use selective search to identify proposals for objects in the scene\n",
    "proposal = []\n",
    "for i_img in [5]:\n",
    "    proposal.append([])\n",
    "    color_img = cv2.cvtColor(X_test_RPN[i_img].astype(np.float32),cv2.COLOR_GRAY2RGB)\n",
    "    img_lbl, regions = selectivesearch.selective_search(color_img, scale=500, sigma=0.9, min_size=100)\n",
    "\n",
    "    print(len(regions))\n",
    "    \n",
    "    # Plot the image and overlay the proposals\n",
    "    plt.figure()\n",
    "    plt.title(f'Image {i_img}, class: {np.argmax(Y_test[i_img])}')\n",
    "    ax = plt.imshow(X_test_RPN[i_img]).axes\n",
    "    for i in range(len(regions)):\n",
    "        \n",
    "        # add bounding box to image\n",
    "        ax.add_patch(matplotlib.patches.Rectangle((regions[i]['rect'][0], regions[i]['rect'][1]),\n",
    "                                                   regions[i]['rect'][2], regions[i]['rect'][3],\n",
    "                                                   fill=False, color='r'))\n",
    "        \n",
    "        # Extract proposed region and store\n",
    "        proposal[-1].append(X_test_RPN[i_img][regions[i]['rect'][1]:regions[i]['rect'][1] + regions[i]['rect'][3],\n",
    "                                regions[i]['rect'][0]:regions[i]['rect'][0] + regions[i]['rect'][2]])\n",
    "        \n",
    "        # Reshape the proposal for classification by our CNN \n",
    "        proposal[-1][-1] = skimage.transform.resize(proposal[-1][-1], (28, 28))\n",
    "        \n",
    "        # Classify as [0-9] or background class. (double expand_dims to correct dimension for CNN [SxHxWxC])\n",
    "        prediction = model.predict(np.expand_dims(np.expand_dims(proposal[-1][-1], axis=0), axis=-1))\n",
    "        \n",
    "        # Plot the proposed region and it's predicted classes based on the CNN model.\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f'Predicted: {np.argmax(prediction)}, Truth: {np.argmax(Y_test[i_img])}')\n",
    "        plt.imshow(skimage.transform.resize(proposal[-1][-1], (28, 28)))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.bar(np.arange(n_class), np.squeeze(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CVDL_Student_Lab5_DeepLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
