{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Vision and Deep Learning \n",
    "## Lab 4 - Feature Descriptors\n",
    "This lab looks into common feature extractors in the vision community. We will look at various filters on static images, and the use of cascade detectors in detection within video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a id=\"imports\"></a>\n",
    "The following section defines the imports used for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For ndarray handling:\n",
    "import numpy as np\n",
    "\n",
    "# For plotting:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For image processing applications\n",
    "import cv2\n",
    "import scipy.signal\n",
    "import skimage\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vase.jpg image\n",
    "We will use a basic image to look at the various filtering operations, but feel free to substitute in your own. Try more complex image structures, do they all work well on noisy images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ademp\\AppData\\Local\\Temp\\ipykernel_13540\\965257731.py:1: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread('foundry.jpg')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'C:\\Users\\ademp\\OptismationCoursework\\Lab4\\foundry.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfoundry.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m image \u001b[38;5;241m=\u001b[39m skimage\u001b[38;5;241m.\u001b[39mcolor\u001b[38;5;241m.\u001b[39mrgb2gray(image)\n\u001b[0;32m      3\u001b[0m figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[1;32mc:\\python\\python380real\\lib\\site-packages\\imageio\\__init__.py:97\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"imread(uri, format=None, **kwargs)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03mReads an image from the specified file. Returns a numpy array, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m    to see what arguments are available for a particular format.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     89\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting with ImageIO v3 the behavior of this function will switch to that of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m iio.v3.imread. To keep the current behavior (and make this warning disappear)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     95\u001b[0m )\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimread_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python380real\\lib\\site-packages\\imageio\\v2.py:226\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m imopen_args \u001b[38;5;241m=\u001b[39m decypher_format_arg(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m    224\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mri\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimopen_args\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m    227\u001b[0m     result \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\python\\python380real\\lib\\site-packages\\imageio\\core\\imopen.py:113\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     request\u001b[38;5;241m.\u001b[39mformat_hint \u001b[38;5;241m=\u001b[39m format_hint\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<bytes>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uri, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m uri\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# fast-path based on plugin\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\python380real\\lib\\site-packages\\imageio\\core\\request.py:247\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[1;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Request.Mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Parse what was given\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Set extension\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\python\\python380real\\lib\\site-packages\\imageio\\core\\request.py:407\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_read_request:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fn):\n\u001b[1;32m--> 407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m fn)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     dn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fn)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'C:\\Users\\ademp\\OptismationCoursework\\Lab4\\foundry.jpg'"
     ]
    }
   ],
   "source": [
    "image = imageio.imread('foundry.jpg')\n",
    "image = skimage.color.rgb2gray(image)\n",
    "figsize = (20,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to view the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zoom_in(image):\n",
    "    '''Nothing fancy here, just slices into a region of the image. \n",
    "    You can tweak this to view other locations.'''\n",
    "    return image[400:1500,400:1500]\n",
    "\n",
    "def threshold(image):\n",
    "    '''Here we use Otsu thresholding to highlight the regions detecting by the \n",
    "    filtering technique. It produces a binary response based on the input.'''\n",
    "    return image <= skimage.filters.threshold_otsu(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Smoothing\n",
    "\n",
    "Here we apply a Guassian kernel to the loaded image, locally smoothing the image features. \n",
    "\n",
    "Try manipulating the sigma, see how it affects the resulting image.\n",
    "Does a bigger sigma result in more blur or less?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_gaussian_filter(kernel_size, sigma):\n",
    "    '''This creates a square kernel_size*kernel_size Gaussian with a given sigma'''\n",
    "    centered_window = (kernel_size-1)/2\n",
    "    kernel_length = np.linspace(-centered_window, centered_window, kernel_size)\n",
    "    gauss_1D = np.exp(-0.5*np.square(kernel_length) / np.square(sigma))\n",
    "    gauss_2D = np.outer(gauss_1D, gauss_1D)\n",
    "    return gauss_2D / np.sum(gauss_2D)\n",
    "\n",
    "sigma = 3\n",
    "kernel_size = int(sigma*3)\n",
    "gaussian_filter = make_gaussian_filter(kernel_size, sigma)\n",
    "\n",
    "# Plot the resulting Gaussian filter\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(gaussian_filter, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Gaussian Kernel')\n",
    "plt.show()\n",
    "\n",
    "gaussian_result = scipy.signal.convolve2d(image, gaussian_filter, mode='valid')\n",
    "\n",
    "# Plot the resulting output\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(gaussian_result, cmap='gray')\n",
    "plt.title('Gaussian Kernel Filtered Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Plot the resulting output (zoomed in)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(zoom_in(image), cmap=plt.cm.gray)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(zoom_in(gaussian_result), cmap=plt.cm.gray)\n",
    "plt.title('Gaussian Filtered')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prewitt Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skimage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Filter the image with a Prewitt filter\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m prewitt_result \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39mprewitt(image)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the original, the filtered image, and the thresholded result\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39mfigsize)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skimage' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter the image with a Prewitt filter\n",
    "prewitt_result = skimage.filters.prewitt(image)\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure(figsize=figsize)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(threshold(prewitt_result), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Plot the resulting output (zoomed in)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(zoom_in(image), cmap=plt.cm.gray)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(zoom_in(threshold(prewitt_result)), cmap=plt.cm.gray)\n",
    "plt.title('Prewitt Filtered')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skimage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Filter the image with a Sobel filter\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sobel_result \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39msobel(image)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the original, the filtered image, and the thresholded result\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39mfigsize)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skimage' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter the image with a Sobel filter\n",
    "sobel_result = skimage.filters.sobel(image)\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure(figsize=figsize)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(threshold(sobel_result), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Plot the resulting output (zoomed in)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(zoom_in(image), cmap=plt.cm.gray)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(zoom_in(threshold(sobel_result)), cmap=plt.cm.gray)\n",
    "plt.title('Sobel Filtered')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the difference between the outputs\n",
    "\n",
    "Here we perform the XOR between the two outputs of Sobel and Prewitt filtering. This should help highlight the different between the two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate difference between the two filtered images.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m thresholded_sobel \u001b[38;5;241m=\u001b[39m \u001b[43mthreshold\u001b[49m(sobel_result)\n\u001b[0;32m      3\u001b[0m thresholded_prewitt \u001b[38;5;241m=\u001b[39m threshold(prewitt_result)\n\u001b[0;32m      4\u001b[0m difference \u001b[38;5;241m=\u001b[39m thresholded_sobel \u001b[38;5;241m^\u001b[39m thresholded_prewitt\n",
      "\u001b[1;31mNameError\u001b[0m: name 'threshold' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate difference between the two filtered images.\n",
    "thresholded_sobel = threshold(sobel_result)\n",
    "thresholded_prewitt = threshold(prewitt_result)\n",
    "difference = thresholded_sobel ^ thresholded_prewitt\n",
    "    \n",
    "# Plot the resulting output (zoomed in)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(difference)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(zoom_in(difference))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skimage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Try the horizontal and vertical Sobel's seperately\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m image_sobel \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39msobel(image)\n\u001b[0;32m      3\u001b[0m image_sobel_h \u001b[38;5;241m=\u001b[39m skimage\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39msobel_h(image)\n\u001b[0;32m      4\u001b[0m image_sobel_v \u001b[38;5;241m=\u001b[39m skimage\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39msobel_v(image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skimage' is not defined"
     ]
    }
   ],
   "source": [
    "# Try the horizontal and vertical Sobel's seperately\n",
    "image_sobel = skimage.filters.sobel(image)\n",
    "image_sobel_h = skimage.filters.sobel_h(image)\n",
    "image_sobel_v = skimage.filters.sobel_v(image)\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure(figsize=figsize)\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(threshold(image_sobel), cmap=plt.cm.gray)\n",
    "plt.title('Sobel Full')\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(threshold(image_sobel_h) , cmap=plt.cm.gray)\n",
    "plt.title('Sobel Horizontal')\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(threshold(image_sobel_v), cmap=plt.cm.gray)\n",
    "plt.title('Sobel Vertical')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skimage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Filter the image with a Laplace filter\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m laplacian_result \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39mlaplace(image, ksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the original, the filtered image, and the thresholded result\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39mfigsize)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skimage' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter the image with a Laplace filter\n",
    "laplacian_result = skimage.filters.laplace(image, ksize=5)\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure(figsize=figsize)\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(image, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(threshold(laplacian_result), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the resulting output (zoomed in)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(zoom_in(image), cmap=plt.cm.gray)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(zoom_in(threshold(laplacian_result)), cmap=plt.cm.gray)\n",
    "plt.title('Laplacian Filtered')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skimage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Filter the image with a Laplace filter\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m laplacian_result \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39mlaplace(image, ksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39mfigsize)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(threshold(laplacian_result), cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mgray)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skimage' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter the image with a Laplace filter\n",
    "laplacian_result = skimage.filters.laplace(image, ksize=3)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(threshold(laplacian_result), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Small Gaussian Sigma\n",
    "sigma = 1\n",
    "kernel_size = int(sigma*3)\n",
    "gaussian_result = scipy.signal.convolve2d(image, make_gaussian_filter(kernel_size, sigma), mode='valid')\n",
    "laplacian_result = skimage.filters.laplace(gaussian_result, ksize=3)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(threshold(laplacian_result), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Larger Gaussian Sigma\n",
    "sigma = 3\n",
    "kernel_size = int(sigma*3)\n",
    "gaussian_result = scipy.signal.convolve2d(image, make_gaussian_filter(kernel_size, sigma), mode='valid')\n",
    "laplacian_result = skimage.filters.laplace(gaussian_result, ksize=3)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(threshold(laplacian_result), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Large Gaussian Sigma and wider kernel\n",
    "sigma = 5\n",
    "kernel_size = int(sigma*5)\n",
    "gaussian_result = scipy.signal.convolve2d(image, make_gaussian_filter(kernel_size, sigma), mode='valid')\n",
    "laplacian_result = skimage.filters.laplace(gaussian_result, ksize=3)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(threshold(laplacian_result), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct comparisons\n",
    "Here we compare the zoomed regions of the different filtering operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'figsize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot the results (zoomed in)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m\u001b[43mfigsize\u001b[49m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(zoom_in(gaussian_result), cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mgray)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'figsize' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the results (zoomed in)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(zoom_in(gaussian_result), cmap=plt.cm.gray)\n",
    "plt.title('Gaussian')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(zoom_in(prewitt_result), cmap=plt.cm.gray)\n",
    "plt.title('Prewitt')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(zoom_in(sobel_result), cmap=plt.cm.gray)\n",
    "plt.title('Sobel')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(zoom_in(laplacian_result), cmap=plt.cm.gray)\n",
    "plt.title('Laplacian')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haar Cascades\n",
    "The following looks at Haar features and their use in tracking of human faces by use of a cascade classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load video in\n",
    "video = cv2.VideoCapture('face.mp4')\n",
    "\n",
    "# Create Haar cascade detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "# Loop over frames in the video and apply cascade detector\n",
    "frames = []\n",
    "n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "for i_frame in range(n_frames):\n",
    "    if not i_frame % 10:\n",
    "        print(f'Processing frame {i_frame} of {n_frames}')\n",
    "    \n",
    "    # Get frame and convert to grayscale\n",
    "    ret, frame = video.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "       \n",
    "    # Detect faces using the cascade\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # For each detected face, annotate the bounding box onto the frame and then try to find the eyes.\n",
    "    for (x,y,w,h) in faces:\n",
    "        # Draw the bounding box onto the frame\n",
    "        img = cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        \n",
    "        # Crop to the detected face, to speed up searching for the eyes\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # Detect eyes in the face using the eye cascade\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "        # Draw the bounding box onto the frame\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex,ey), (ex+ew,ey+eh), (0,255,0), 2)\n",
    "            \n",
    "    # Add frame to our list of annotated frames\n",
    "    frames.append(frame)\n",
    "    \n",
    "# View result\n",
    "for i_frame in frames:\n",
    "    # Render the frame\n",
    "    cv2.imshow('img',i_frame)\n",
    "    cv2.waitKey(30)\n",
    "\n",
    "# Close everything once finished\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following looks at Haar features and their use in tracking of human bodies by use of a cascade classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load video in\n",
    "video = cv2.VideoCapture('human.mp4')\n",
    "\n",
    "# Create Haar cascade detector\n",
    "body_cascade = cv2.CascadeClassifier('haarcascade_fullbody.xml')\n",
    "\n",
    "# Loop over frames in the video and apply cascade detector\n",
    "frames = []\n",
    "n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "for i_frame in range(n_frames):\n",
    "    if not i_frame % 10:\n",
    "        print(f'Processing frame {i_frame} of {n_frames}')\n",
    "    \n",
    "    # Get frame and convert to grayscale\n",
    "    ret, frame = video.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "       \n",
    "    # Detect bodies using the cascade\n",
    "    bodies = body_cascade.detectMultiScale(gray)\n",
    "    \n",
    "    # Draw the bounding box onto the frame\n",
    "    for (x,y,w,h) in bodies:\n",
    "        img = cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        \n",
    "    # Add frame to our list of annotated frames\n",
    "    frames.append(frame)\n",
    "    \n",
    "# View result\n",
    "for i_frame in frames:\n",
    "    # Render the frame\n",
    "    cv2.imshow('img', i_frame)\n",
    "    cv2.waitKey(30)\n",
    "\n",
    "# Close everything once finished\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoG Features\n",
    "The following utilises the Histogram of Gradients feature extractor on the given image. We can then look at varying the hyperparameters to observe the impact on retained details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imageio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load in a smaller image for this example\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mimageio\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvase.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m skimage\u001b[38;5;241m.\u001b[39mcolor\u001b[38;5;241m.\u001b[39mrgb2gray(image)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extract HoG features and obtain both the vector and the HoG visualization image\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imageio' is not defined"
     ]
    }
   ],
   "source": [
    "# Load in a smaller image for this example\n",
    "image = imageio.imread('vase.jpg')\n",
    "image = skimage.color.rgb2gray(image)\n",
    "\n",
    "# Extract HoG features and obtain both the vector and the HoG visualization image\n",
    "hog, hogvis = skimage.feature.hog(image, visualize=True)\n",
    "\n",
    "# Plot the original and the HoG rose plots\n",
    "plt.figure(figsize=figsize)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(hogvis, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skimage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hog1, hogvis1 \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mhog(image, pixels_per_cell\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m), visualize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m hog2, hogvis2 \u001b[38;5;241m=\u001b[39m skimage\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mhog(image, pixels_per_cell\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m), visualize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m hog3, hogvis3 \u001b[38;5;241m=\u001b[39m skimage\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mhog(image, pixels_per_cell\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m), visualize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skimage' is not defined"
     ]
    }
   ],
   "source": [
    "hog1, hogvis1 = skimage.feature.hog(image, pixels_per_cell=(32,32), visualize=True)\n",
    "hog2, hogvis2 = skimage.feature.hog(image, pixels_per_cell=(16,16), visualize=True)\n",
    "hog3, hogvis3 = skimage.feature.hog(image, pixels_per_cell=(2,2), visualize=True)\n",
    "\n",
    "# Plot the various HoG results with differing cell sizes\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(hogvis1, cmap=plt.cm.gray)\n",
    "plt.title(f'Size of vector when using (32,32): {hog1.shape}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(hogvis2, cmap=plt.cm.gray)\n",
    "plt.title(f'Size of vector when using (16,16): {hog2.shape}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(hogvis3, cmap=plt.cm.gray)\n",
    "plt.title(f'Size of vector when using (2,2): {hog3.shape}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
