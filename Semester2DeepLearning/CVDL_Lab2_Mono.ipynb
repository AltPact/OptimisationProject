{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision and Deep Learning \n",
    "## Lab 2 &ndash; Mono Camera Calibration Example\n",
    "This lab looks into calibrating camera systems. To this end we want to utilise corresponding points within a set of images to help identify intrinsic parameters linking the cameras in the real-world.\n",
    "\n",
    "There are two ways to approach this lab. You can either grab the calibration board from the front and grab a series of images from the KinectV2 using code similar to the first lab, or you can utilise the data I have captured myself. Both will then be used in the same way later on, but it may be nice to have a bit of personalisation for the data you will be using.\n",
    "\n",
    "First we need to obtain some images, identify a checkerboard pattern on the RGB image maps and then register the points identifed on the checkerboard across the different images. \n",
    "\n",
    "We will utilize OpenCV functionality to undertake a large portion of the pipeline, and then later we will visualise the two x-centric viewpoints we can make from these observations. Camera-centric and Board-centric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a id=\"imports\"></a>\n",
    "The following section defines the imports used for the rest of the notebook. \n",
    "\n",
    "You shouldn't need to change much here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing open3d: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m coloration \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([elem[:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m cmap\u001b[38;5;241m.\u001b[39mcolors])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# For 3D visualisation:\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopen3d\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mo3d\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# For image processing applications and camera calibration:\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\open3d\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopen3d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmacos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopen3d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwin32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\open3d\\win32\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen3d.win32.32b.open3d\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39marchitecture()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m64bit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopen3d.win32.64b.open3d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\open3d\\win32\\64b\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Open3D: www.open3d.org\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# The MIT License (MIT)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# See license file or visit www.open3d.org for details\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopen3d.win32.64b.open3d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing open3d: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "# For ndarray handling:\n",
    "import numpy as np\n",
    "\n",
    "# For plotting:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For nice camera plotting colors:\n",
    "from matplotlib.colors import BASE_COLORS, to_rgb\n",
    "color_names = list(BASE_COLORS)[:-1] # remove the 'w' color\n",
    "color_list = [to_rgb(color) for color in color_names]\n",
    "\n",
    "# For nice smooth colorbar\n",
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap('viridis', 6*9) # come back to this later\n",
    "coloration = np.vstack([elem[:3] for elem in cmap.colors])\n",
    "\n",
    "# For 3D visualisation:\n",
    "import open3d as o3d\n",
    "\n",
    "# For image processing applications and camera calibration:\n",
    "import cv2\n",
    "\n",
    "# For reading and writing images:\n",
    "import imageio\n",
    "\n",
    "# For Operating System tools and file finding:\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved images from the disk\n",
    "\n",
    "This code will load saved images from disk. These could be images that you have downloaded from Canvas, or images saved from a previous session.\n",
    "\n",
    "We expect a height x width x channel tensor, although a height x width matrix will be expanded to include a singleton channel. \n",
    "\n",
    "For the provided images the sizes are: \n",
    "* Colour image size: 1080 (height) by 1920 (width) by 3 (channel, RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get list of filenames for photos with checkerboard pattern.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m path_to_data \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mgetcwd() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCVDL_Lab2_Data\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Edit this if data is another directory.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m filenames \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(path_to_data \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m*.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m n_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(filenames)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Get list of filenames for photos with checkerboard pattern.\n",
    "path_to_data = os.getcwd() + '\\CVDL_Lab2_Data' # Edit this if data is another directory.\n",
    "filenames = glob.glob(path_to_data + '\\*.png')\n",
    "n_files = len(filenames)\n",
    "\n",
    "# Load the files from disk into np ndarrays.\n",
    "images = []\n",
    "for i_file in range(n_files):\n",
    "    images.append(imageio.imread(filenames[i_file]))\n",
    "    print(f'Loaded image {i_file} of {n_files}')\n",
    "\n",
    "# Check first image shape, and ensure that it is a rank 3 tensor.\n",
    "if len(images[0].shape) == 2:\n",
    "    images = [np.expand_dims(image, -1) for image in images]\n",
    "\n",
    "# Create some shape constants for use later.\n",
    "IMG_H, IMG_W, IMG_C = images[0].shape\n",
    "print(f'Image shapes are: {images[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot frames\n",
    "In this following section we want to plot the images we have taken. This should only include images of checkerboard calibration patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new figure and calculate how many rows and columns are to be plotted.\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "n_subplot_cols = 3\n",
    "n_subplot_rows = np.ceil(n_files/n_subplot_cols).astype(np.int)\n",
    "\n",
    "# Loop over our captured frames, and subplot each image.\n",
    "for i_file in range(n_files):\n",
    "    plt.subplot(n_subplot_rows, n_subplot_cols, i_file+1)\n",
    "    plt.imshow(images[i_file])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect the checkerboard pattern in an image\n",
    "Using OpenCV, we can use the `findChessboardCorners()` method to identify a standard checkerboard pattern, commonly by identification of Harris corners. This method takes in the orignal image in grayscale, which we use `cvtColor` to achieve, and a tuple of the internal corner counts `checkerboard_pattern`.\n",
    "\n",
    "The method takes in the following: \n",
    "* image - An image potentially containing a chessboard pattern.\n",
    "* patternSize - A tuple describing the number of inner corners to be detected in the image, given by (points_per_row, points_per_column).\n",
    "\n",
    "Further detail on this method can be found at https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga93efa9b0aa890de240ca32b11253dd4a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  TODO: Provide the correct checkerboard corner pattern tuple, as described above.\n",
    "checkerboard_pattern =  [8,8]\n",
    "\n",
    "# Detect checkerboard in each image\n",
    "image_corners = []\n",
    "\n",
    "for i_file in range(n_files):\n",
    "    \n",
    "    # Grayscale the image if needed.\n",
    "    image = images[i_file]\n",
    "    if IMG_C == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    # Detect the corners in the image.\n",
    "    pattern_found, image_corner = cv2.findChessboardCorners(image, checkerboard_pattern) # Locate pattern in image\n",
    "    \n",
    "    if pattern_found:\n",
    "        # Likely don't need to refine, but if needed then uncomment these two lines.\n",
    "        #subpixel_criteria =  (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001) # Stopping criteria for refinement\n",
    "        #img_corner = cv2.cornerSubPix(image, img_corner, (11, 11), (-1, -1), subpixel_criteria)\n",
    "        \n",
    "        # Add detected corners into list.\n",
    "        image_corners.append(image_corner[::-1])\n",
    "        \n",
    "        # Vizualise the detected patterns.\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        corners = np.squeeze(image_corners[-1])\n",
    "        plt.scatter(corners[:, 0], corners[:, 1], s=50, c=coloration)\n",
    "        \n",
    "        # Add annotations to the image for clarity.\n",
    "        for i_corner in range(corners.shape[0]):\n",
    "            plt.text(corners[i_corner,0], corners[i_corner, 1], f'{i_corner}')\n",
    "        plt.axis('off')\n",
    "\n",
    "n_successes = len(image_corners)\n",
    "print('Number of successfully found patterns is: {0} out of {1}'.format(n_successes, n_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate camera using detected patterns\n",
    "The following cell looks to calibrate the camera using using the identified corners from the patterns on the calibration board in each image.\n",
    "\n",
    "First we build a coordinate system for the pattern, this requires specifying the 3D points of the corners on the board from the board's world coordinate system. For example: if we have a board of size (3, 2) we would specify corners at: \n",
    "    [[0, 0], [0, 1], [0, 2], \n",
    "     [1, 0], [1, 1], [1, 2]]\n",
    "\n",
    "Next we use OpenCV functionality to calibrate the camera with the `calibrateCamera()` function. This returns the intrinsic camera matrix, the distortion coefficients for our camera, and the rotation and translation vectors for each board. API for `calibrateCamera()`: https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga687a1ab946686f0d85ae0363b5af1d7b Your job here is to figure out which of the returned arguments is the intrinsic matrix.\n",
    "\n",
    "We then create a dictionary, `camera_extrinsics`, containing the extrinsic parameters for each set of points found. This contains the rotation matrix and translation vector. Note here that we turn the rotation vectors `r_vec` into the rotation matrix using the `Rodrigues()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the coordinate points of our checkerboard pattern (meshgrid makes this easier)\n",
    "SQUARE_H = 1 # Height of the squares on the board.\n",
    "SQUARE_W = SQUARE_H\n",
    "board = np.zeros((np.product(checkerboard_pattern), 3), dtype=np.float32)\n",
    "row_points, col_points = np.meshgrid(np.arange(0, SQUARE_H * checkerboard_pattern[0], SQUARE_H),\n",
    "                                     np.arange(0, SQUARE_W * checkerboard_pattern[1], SQUARE_W))\n",
    "\n",
    "# Create board by stacking the coordinate mesh.\n",
    "board = np.stack([row_points.flatten(), \n",
    "                  col_points.flatten(),\n",
    "                  np.zeros_like(row_points.flatten())], axis=-1)\n",
    "\n",
    "# Cast to float32 for calibration.\n",
    "board = board.astype(np.float32)\n",
    "\n",
    "# Create a list of the checkerboard patterns by duplicating it for each successfully detected chessboard.\n",
    "boards = [board for i in range(n_successes)]\n",
    "\n",
    "# Calibrate camera.\n",
    "retval, cameraMatrix, distortion, r_vec, t_vec = cv2.calibrateCamera(boards, image_corners, [IMG_W, IMG_H], None, None)\n",
    "\n",
    "# Store camera intrinsic matrix.\n",
    "# TODO: Identify the camera's intrinsic matrix from the list of variables returned by the calibrateCamera method above.\n",
    "camera_intrinsic = []\n",
    "\n",
    "# Store camera extrinsic matrices.\n",
    "camera_extrinsics = {'rotation_matrix' : [],\n",
    "                     'translation_matrix' : []}\n",
    "\n",
    "for i_board in range(n_successes):\n",
    "    camera_extrinsics['rotation_matrix'].append(np.asarray(cv2.Rodrigues(r_vec[i_board])[0]))\n",
    "    camera_extrinsics['translation_matrix'].append(np.asarray(t_vec[i_board]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate boards to world coordinate system and plot camera-centric viewpoint\n",
    "In this cell we will transform the board coordinate system into the world coordinate system of the camera. We can then plot these points in the 3D space relative to our camera centred at (0, 0, 0). This makes the assumption that our camera is fixed and we move our checkerboard pattern around.\n",
    "\n",
    "We loop over our identified board patterns and translate them into the camera's world coordinate system via the rotation and translation identified via calibration.\n",
    "\n",
    "Your job here is apply the rotation and translation of the board's coordinates into the world coordinate system. Open3D's PointCloud object has two methods which are useful. Be sure to think about where the origin may be. You will also need to visualise the camera within the scene, this requires knowing the size of the image and the camera intrinsics (sound familiar?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base board pointcloud object, this will then be duplicated and placed into our camera coordinate system.\n",
    "board_pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(board))\n",
    "\n",
    "# Add each of the boards to their position in the scene.\n",
    "pcd = []\n",
    "for i_board in range(n_successes):\n",
    "    \n",
    "    # Obtain the rotation matrices and translation vectors for each board.\n",
    "    R = camera_extrinsics['rotation_matrix'][i_board]\n",
    "    T = camera_extrinsics['translation_matrix'][i_board]\n",
    "    \n",
    "    # Move board coordinates to camera coordinate system.\n",
    "    # TODO: Apply the necessary projection of the board into the scene.\n",
    "    #       Open3D has two ways to do this: one uses two method calls, the other uses only one.\n",
    "    #       Either way you use is okay. \n",
    "    #       Slide 8 will help you here. As will the Open3D PointCloud API at:\n",
    "    #       http://www.open3d.org/docs/release/python_api/open3d.geometry.PointCloud.html\n",
    "    i_board_pcd = o3d.geometry.PointCloud(board_pcd)\n",
    "    i_board_pcd = 'TODO' # Move the points into the camera coordinate system. \n",
    "    \n",
    "    # Add the ith board to the scene and give it a color.\n",
    "    pcd.append(i_board_pcd)\n",
    "    pcd[-1].paint_uniform_color(color_list[i_board % (len(color_list))])\n",
    "    \n",
    "    # Add the board's coordinate origin to the scene (in the correct place).\n",
    "    # TODO: Apply the necessary projection of the board's origin into the scene.\n",
    "    #       This will be very similar to the above.\n",
    "    board_origin = o3d.geometry.TriangleMesh.create_coordinate_frame()\n",
    "    board_origin = 'TODO'\n",
    "    pcd.append(board_origin)\n",
    "    \n",
    "# Add a visual representation of our camera into the scene.\n",
    "# TODO: Here you will need to identify the required parts of the intrinsic matrix.\n",
    "#       Open3D won't let you just put the 3x3 matrix in, you will need to pass them in by parameter.\n",
    "#       Slide 13 should help you here.\n",
    "o3d_cam_intrinsic = o3d.camera.PinholeCameraIntrinsic(width='TODO',\n",
    "                                                      height='TODO',\n",
    "                                                      fx='TODO',\n",
    "                                                      fy='TODO',\n",
    "                                                      cx='TODO',\n",
    "                                                      cy='TODO')\n",
    "\n",
    "# Add the camera and it's coordinate origin to the scene. \n",
    "pcd.append(o3d.geometry.LineSet.create_camera_visualization(o3d_cam_intrinsic, np.eye(4), scale=1))\n",
    "pcd.append(o3d.geometry.TriangleMesh.create_coordinate_frame())\n",
    "\n",
    "# Visualize the PointCloud.\n",
    "o3d.visualization.draw_geometries(pcd,\n",
    "                                  lookat=np.asarray([ 0.0, 0.0, 0.0]),\n",
    "                                  up=np.asarray([0.0, -1.0, 0.0]),\n",
    "                                  front=np.asarray([0.0, 0.0, -1.0]),\n",
    "                                  zoom=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate cameras and plot the pattern-centric viewpoints\n",
    "In this cell we will transform the camera coordinate system into the world coordinate system of the board. We can then plot these points in the 3D space relative to our board centred at (0, 0, 0). This makes the assumption that our pattern is fixed and we move our camera around.\n",
    "\n",
    "We loop over each camera viewpoint in our identified board patterns and translate them into the board's world coordinate system via the inversed of the translation and rotation identified via calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our single board to the scene. Give it a smooth color so we can see which way up it is.\n",
    "pcd = []\n",
    "board_pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(board))\n",
    "board_pcd.colors = o3d.utility.Vector3dVector(coloration)\n",
    "pcd.append(board_pcd)\n",
    "\n",
    "# TODO: Here you will need to identify the required parts of the intrinsic matrix.\n",
    "#       This is the same as in the previous cell.\n",
    "o3d_cam_intrinsic = o3d.camera.PinholeCameraIntrinsic(width='TODO',\n",
    "                                                      height='TODO',\n",
    "                                                      fx='TODO',\n",
    "                                                      fy='TODO',\n",
    "                                                      cx='TODO',\n",
    "                                                      cy='TODO')\n",
    "\n",
    "# Add the coordinate origin of the board to the scene. \n",
    "pcd.append(o3d.geometry.TriangleMesh.create_coordinate_frame())\n",
    "\n",
    "for i_camera in range(n_successes):\n",
    "    \n",
    "    # Obtain the rotation matrices and translation vectors for each camera.\n",
    "    R = camera_extrinsics['rotation_matrix'][i_camera]\n",
    "    T = camera_extrinsics['translation_matrix'][i_camera]\n",
    "    \n",
    "    # Open3D requires a 4x4 camera extrinsic matrix, rather than the expected 3x4. Why?\n",
    "    cam_extrinsic = np.vstack([np.hstack([R, T]),\n",
    "                               np.asarray([0, 0, 0, 1])])\n",
    "    \n",
    "    # Create a visualisation of the ith camera in the scene, with a nice color.\n",
    "    pcd.append(o3d.geometry.LineSet.create_camera_visualization(o3d_cam_intrinsic, cam_extrinsic, scale=1))\n",
    "    pcd[-1].paint_uniform_color(color_list[i_camera % (len(color_list))])\n",
    "    \n",
    "    # Add the camera coordinate origin to the scene. \n",
    "    camera_origin = o3d.geometry.TriangleMesh.create_coordinate_frame()\n",
    "    camera_origin = camera_origin.translate(-T)\n",
    "    camera_origin = camera_origin.rotate(R.T, [0,0,0])\n",
    "    pcd.append(camera_origin)\n",
    "    \n",
    "\n",
    "# Visualize the PointCloud.\n",
    "o3d.visualization.draw_geometries(pcd,\n",
    "                                  lookat=np.asarray([ 0.0, 0.0, 0.0]),\n",
    "                                  up=np.asarray([0.0, -1.0, 0.0]),\n",
    "                                  front=np.asarray([0.0, 0.0, -1.0]),\n",
    "                                  zoom=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "29828b97129c066cf5d4d8ed5b468530063fef82adb70207f83f2e532bdf5c80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
